# ResNet-based CVAE
This is an implementation of custom `ResNet-based CVAE` to generate synthetic images.

## Training the Model
### ğŸ”§ Training
```bash
python main.py fit --config config/train.yaml
```

### ğŸ”§ Training from a checkpoint
```bash
python main.py fit --config config/train.yaml --ckpt_path runs/train_/checkpoints/interval/hsdt-epoch10.ckpt
```

### ğŸ”§ Smoke Test
```bash
python main.py fit --config config/train_local.yaml --trainer.profiler=null --trainer.fast_dev_run=True
```

### ğŸ”§ Best batch finder
```bash
python main.py fit --config config/train.yaml --run_batch_size_finder true --batch_size_finder_mode power
```

### ğŸ”§ Best learning rate finder
```bash
python main.py fit --config config/train.yaml --run_lr_finder true 
```

## Running the Model
### âœ… Validation
```bash
python main.py validate --config config/train.yaml
```

### ğŸ§ª Testing
```bash
python main.py test --config config/train.yaml
```

### ğŸ”® Predict
```bash
python main.py predict --config config/predict.yaml
```

### ğŸ†˜ For help text
```bash
python main.py --help
```
Note that all the individual commands also have `--help`

## Log Analysis
```bash
tensorboard --logdir runs
```

## Architecture
```d
Input x âˆˆ R^{BÃ—1Ã—28Ã—28}                                  Class label c âˆˆ {0..9}
        â”‚                                                          â”‚
        â”‚                                                          â””â”€ one-hot(10) â†’ Linear(10â†’16) â†’ SiLU â†’ e âˆˆ R^{BÃ—16}
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ResNet Feature Extractor (Encoder CNN) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                                                      â”‚
        â”‚  Stem: Conv 3Ã—3, s1, p1, c=32 â†’ GroupNorm(8) â†’ SiLU                  â”‚
        â”‚    â””â”€ out: (B,32,28,28)                                              â”‚
        â”‚
        â”‚  ResBlockâ†“ (32â†’32):                                                  â”‚
        â”‚    Main: Conv 3Ã—3, s2, p1, c=32 â†’ GN â†’ SiLU â†’ Conv 3Ã—3, s1, p1, c=32 â”‚
        â”‚    Skip: Conv 1Ã—1, s2, p0, c=32                                      â”‚
        â”‚    Add â†’ SiLU                                                        â”‚
        â”‚    â””â”€ out: (B,32,14,14)                                              â”‚
        â”‚
        â”‚  ResBlockâ†“ (32â†’64):                                                  â”‚
        â”‚    Main: Conv 3Ã—3, s2, p1, c=64 â†’ GN â†’ SiLU â†’ Conv 3Ã—3, s1, p1, c=64 â”‚
        â”‚    Skip: Conv 1Ã—1, s2, p0, c=64                                      â”‚
        â”‚    Add â†’ SiLU                                                        â”‚
        â”‚    â””â”€ out: (B,64,7,7)                                                â”‚
        â”‚
        â”‚  ResBlock  (64â†’64):                                                  â”‚
        â”‚    Main: Conv 3Ã—3, s1, p1, c=64 â†’ GN â†’ SiLU â†’ Conv 3Ã—3, s1, p1, c=64 â”‚
        â”‚    Skip: Identity                                                    â”‚
        â”‚    Add â†’ SiLU                                                        â”‚
        â”‚    â””â”€ out: (B,64,7,7)                                                â”‚
        â”‚
        â”‚  GlobalAvgPool (7Ã—7 â†’ 1Ã—1): out (B,64)                               â”‚
        â”‚
        â”œâ”€[concat]â†’ h = concat( (B,64), e:(B,16) ) â†’ (B,80)                    â”‚  â† (class-aware encoder head)
        â”‚
        â”œâ”€ Î¼ = Linear(80â†’z)                                                    â”‚
        â”œâ”€ logÏƒÂ² = Linear(80â†’z)                                                â”‚
        â”‚
        â””â”€ Reparameterization: z = Î¼ + exp(0.5Â·logÏƒÂ²) âŠ™ Îµ,  Îµ~N(0,I)  (B,z) â”€â”€â”€â”˜

                                  â–¼

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Decoder CNN (ResNet Upsampling) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚                                                                â”‚
                 â”‚  zâ€™ = concat( z:(B,z), e:(B,16) ) â†’ Linear((z+16) â†’ 7Ã—7Ã—64)    â”‚
                 â”‚  Reshape â†’ (B,64,7,7)                                          â”‚
                 â”‚
                 â”‚  ResBlockâ†‘ (64â†’64):                                            â”‚
                 â”‚    UpÃ—2 â†’ Conv 3Ã—3, s1, p1, c=64 â†’ GN â†’ SiLU â†’ Conv 3Ã—3, s1,p1 â”‚
                 â”‚    Skip: UpÃ—2 â†’ Conv 1Ã—1, s1, p0, c=64                         â”‚
                 â”‚    Add â†’ SiLU                                                  â”‚
                 â”‚    â””â”€ out: (B,64,14,14)                                        â”‚
                 â”‚
                 â”‚  ResBlockâ†‘ (64â†’32):                                            â”‚
                 â”‚    UpÃ—2 â†’ Conv 3Ã—3, s1, p1, c=32 â†’ GN â†’ SiLU â†’ Conv 3Ã—3, s1,p1 â”‚
                 â”‚    Skip: UpÃ—2 â†’ Conv 1Ã—1, s1, p0, c=32                         â”‚
                 â”‚    Add â†’ SiLU                                                  â”‚
                 â”‚    â””â”€ out: (B,32,28,28)                                        â”‚
                 â”‚
                 â”‚  Conv 1Ã—1, s1, p0, c=1 â†’                                      â”‚
                 â”‚     â€¢ Sigmoid  (if Bernoulli likelihood, x âˆˆ [0,1])            â”‚
                 â”‚     â€¢ Identity (if Gaussian with fixed Ïƒ, x âˆˆ [-1,1])          â”‚
                 â”‚
                 â””â”€ Reconstruction Å· âˆˆ R^{BÃ—1Ã—28Ã—28} â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Loss:  L =  E_{q(z|x,c)}[ âˆ’log p( x | z,c ) ]  +  Î² Â· KL( q(z|x,c) || N(0,I) )
       (Use Î²=1 with KL warm-up; or Î²â‰ˆ2â€“4 for stronger regularization)

Defaults / Hyperparams:
  â€¢ z-dim: 16 (try 32 as ablation)       â€¢ Activation: SiLU (ReLU also fine)
  â€¢ Norm: GroupNorm(8) (BatchNorm OK if large batch)
  â€¢ Optim: AdamW (lr=2e-3, wd=1e-4)      â€¢ Grad clip: 1.0
  â€¢ Batch: 128                           â€¢ Epochs: 50â€“100 (MNIST)
```

