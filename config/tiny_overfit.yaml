# tiny_overfit.yaml
seed_everything: 42

model:
  beta: 0.0            # disable KL
  kl_warmup_epochs: 0  # no warm-up
  lr: 2e-3             # learn fast for small data
  weight_decay: 1e-4
  use_film: false
  loss:
    name: standard

data:
  batch_size: 64
  val_split: 59872     # 60000 - 128 = 128 train samples
  num_workers: 0       # keep IO simple while debugging
  pin_memory: false
  persistent_workers: false

  # Controlling the output
  predict_classes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
  temperature: 0
  guidance_scale: 0
  cond_scale: 1.0
  predict_samples_per_class: 8

trainer:
  max_epochs: 20
  log_every_n_steps: 1
  limit_val_batches: 0.0      # optional: skip val to focus on train
  limit_test_batches: 0.0
  deterministic: true
