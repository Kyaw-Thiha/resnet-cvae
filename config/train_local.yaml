# Seed everything (LightningCLI handles this when set here)
seed_everything: 42

# ----------------------------
# Model hyperparameters
# ----------------------------
model:
  in_channels: 1            # set to 3 for RGB datasets later
  out_channels: 1
  z_dim: 16
  num_classes: 10
  cond_dim: 16
  use_film: false
  sigma: 0.1

  # Optimization + loss schedule
  lr: 1.74e-04                 # TODO: Update the learning rate based on learning rate finder
  weight_decay: 0.0001
  beta: 0.8                 # final KL weight [0.5 ~ 1]
  kl_warmup_epochs: 50      # linear warmup from 0 -> beta
  max_epochs: 100            # (used by the cosine LR helper)

# ----------------------------
# Data settings
# ----------------------------
data:
  data_dir: ./data
  batch_size: 1024          # TODO: Update the batch size based on batch size finder
  num_workers: 8
  val_split: 5000
  image_channels: 1         # keep in sync with model.{in,out}_channels
  num_classes: 10
  predict_samples_per_class: 8
  pin_memory: true
  persistent_workers: true

# ----------------------------
# Trainer configuration
# ----------------------------
trainer:
  default_root_dir: runs
  accelerator: auto
  devices: auto
  max_epochs: 300
  precision: 32-true
  log_every_n_steps: 50
  gradient_clip_val: 1.0
  deterministic: false
  enable_checkpointing: true
  default_root_dir: ./runs

